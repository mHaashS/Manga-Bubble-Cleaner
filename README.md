# Manga-Bubble-Cleaner
### Objectif global
Cr√©er un pipeline automatis√© pour :

- D√©tecter les bulles dans des pages de manga (bubbles, narration, floating text)
- Nettoyer ces bulles (effacement ou inpainting)
- Extraire le texte original (OCR)
- Le traduire automatiquement
- G√©n√©rer des fichiers .txt + .json qui contiennent le texte original et traduit (au cas o√π la traduction automatique est incorrecte ou incompl√®te) et la position des bulles
- R√©ins√©rer le texte dans l‚Äôimage avec la position dans le json

## Table des mati√®res

## Table des mati√®res

- [√âtape 1 ‚Äî Entra√Ænement du mod√®le](#√©tape-1--entra√Ænement-du-mod√®le)  
- [√âtape 2 ‚Äî Observation des pr√©dictions du mod√®le](#√©tape-2--observation-des-pr√©dictions-du-mod√®le)  
- [√âtape 3 ‚Äî Nettoyage visuel des bulles](#√©tape-3--nettoyage-visuel-des-bulles)  
- [√âtape 4 ‚Äî Extraction du texte + Traduction automatique](√©tape-4--extraction-du-texte--traduction-automatique)  
- [√âtape 5 ‚Äî R√©insertion du texte traduit dans les bulles](#√©tape-5--r√©insertion-du-texte-traduit-dans-les-bulles)  

- [Cloner le d√©p√¥t](#cloner-le-d√©p√¥t)  
- [Technologies utilis√©es](#technologies-utilis√©es)

## √âtape 1 ‚Äî Entra√Ænement du mod√®le
Objectif :
D√©tecter automatiquement les bulles dans les pages de manga avec un mod√®le Mask R-CNN personnalis√©.

üß™ Mise en ≈ìuvre
Annotations faites via CVAT, export√©es au format COCO JSON

Les classes sont :
- bubble (attributs : normal, cri, malade)
- floating_text (attributs : titre, cri, narration)
- narration_box (sans attribut)

Lors de l'annotation des donn√©es sur CVAT, j'avais initialement ajout√© des attributs personnalis√©s √† certaines classes, comme :
bubble ‚Üí {normal, cri, malade}
floating_text ‚Üí {titre, narration, cri}
Cependant, je me suis rendu compte trop tard que Detectron2 ne prend pas en compte les attributs COCO dans son format d'entra√Ænement.
Seuls les labels (classes) sont utilis√©s, ce qui signifie que ces attributs ont √©t√© ignor√©s lors de l'entra√Ænement.

Le script enregistre deux datasets :
register_coco_instances("manga_train", {}, annotations_train.json, images/)
register_coco_instances("manga_val", {}, annotations_val.json, images/)
Le mod√®le Mask R-CNN est entra√Æn√© avec les 3 classes.

Le mod√®le est sauvegard√© dans : output/model_final.pth

## √âtape 2 ‚Äî Observation des pr√©dictions du mod√®le
Apr√®s avoir entra√Æn√© mon mod√®le, j‚Äôai voulu m‚Äôassurer qu‚Äôil √©tait capable de reconna√Ætre visuellement les bulles dans une page de manga.
Pour cela, j‚Äôai pr√©par√© quelques images de test, puis j‚Äôai lanc√© le mod√®le pour voir o√π et comment il d√©tectait les objets.

L‚Äôobjectif n‚Äô√©tait pas encore de nettoyer ou traduire quoi que ce soit, mais simplement de :
- Valider que les bulles √©taient bien reconnues
- Voir si les masques collaient bien aux contours r√©els
- Et v√©rifier si le mod√®le faisait des erreurs (oubli, confusion...)

J‚Äôai visualis√© les pr√©dictions sur les images avec des couleurs diff√©rentes pour chaque type de bulle (bulles classiques, floating text, narration).
Cela m‚Äôa permis de juger rapidement :
- Si la qualit√© de l'entra√Ænement √©tait suffisante
- Si les annotations initiales √©taient coh√©rentes
- Et si je pouvais passer √† l‚Äô√©tape suivante

Pour les pages avec des bulles simples, le mod√®le arrive facilement √† reconnaitre les bulles.

![image1](https://github.com/user-attachments/assets/121673fe-a03b-4f78-9d34-e18871854b21)

La t√¢che se complique un peu quand il s'attaque √† des floating_text.
Surement du au fait qu'il y avait moins de data avec des floating_text.

![image2](https://github.com/user-attachments/assets/30997745-2115-4465-b0b0-148027ca5779)


## √âtape 3 ‚Äî Nettoyage visuel des bulles
Une fois que j‚Äô√©tais satisfait de la d√©tection des bulles, j‚Äôai voulu effacer le texte qu‚Äôelles contiennent.
L‚Äôobjectif ici n‚Äô√©tait pas encore d‚Äôextraire le texte, mais simplement de vider les bulles pour pouvoir y ins√©rer du texte plus tard.

Plut√¥t que de supprimer toutes les zones d√©tect√©es de la m√™me mani√®re, j‚Äôai choisi une approche adapt√©e au type de bulle :
- Pour les bulles classiques et les bo√Ætes de narration, j‚Äôai simplement rempli la zone avec une couleur blanche.
- Pour les floating text (souvent du texte sans contour net), j‚Äôai utilis√© une technique qui essaie de reconstruire le fond de l‚Äôimage en supprimant le texte (inpainting) mais qui n'est pas au point.

Cette √©tape m‚Äôa permis de visualiser une page nettoy√©e de tout son texte, tout en gardant la structure des bulles intacte
Cela a √©t√© essentiel pour pr√©parer l‚Äôinsertion future du texte traduit.
J‚Äôai aussi fix√© un seuil de confiance √† 75% pour ne nettoyer que les bulles dont le mod√®le √©tait suffisamment s√ªr, afin d‚Äô√©viter d‚Äôeffacer des parties incorrectes.

![image3](https://github.com/user-attachments/assets/693c22b3-4398-4798-8222-fa7ae7d91cb5)
![image4](https://github.com/user-attachments/assets/c04343a7-7479-4693-8a9e-76a2465fc467)

## √âtape 4 ‚Äî Extraction du texte + Traduction automatique
Une fois les bulles d√©tect√©es sur une page de manga, j‚Äôai automatis√© un processus en deux temps :
üîç lire le texte pr√©sent dans chaque bulle, puis üåç le traduire automatiquement en fran√ßais.

J‚Äôai regroup√© ces deux √©tapes dans un seul script, qui prend une image en entr√©e et produit un fichier .txt et .json comme sortie.

üß™ √âtapes du traitement
Pour chaque bulle d√©tect√©e :
- Extraction de la zone √† partir du masque de segmentation
- D√©coupage de la zone dans l‚Äôimage (ROI)

Application d‚ÄôEasyOCR :
- OCR robuste, sans pr√©traitement n√©cessaire
- Capable de lire du texte stylis√© et irr√©gulier
- R√©sultat brut nettoy√© (espaces multiples, retours √† la ligne, etc.)

Traduction automatique :
- Traduction du texte anglais vers le fran√ßais
- R√©alis√©e via l‚ÄôAPI OpenAI (GPT-3.5)
- Le texte original et sa traduction sont tous deux enregistr√©s

Export des r√©sultats :
- En .txt lisible pour l‚Äôutilisateur
- En .json structur√© pour usage automatis√©
  
![image5](https://github.com/user-attachments/assets/89ffcd4e-02e1-4dfa-bb3c-f1537178c068)

## √âtape 5 ‚Äî R√©insertion du texte traduit dans les bulles

Apr√®s avoir d√©tect√©, nettoy√© et traduit les bulles de texte dans les pages de manga, l‚Äôobjectif final est de **r√©ins√©rer automatiquement le texte traduit dans l‚Äôimage nettoy√©e**, √† l‚Äôendroit exact o√π se trouvait le texte original.

Cette √©tape transforme r√©ellement le pipeline : on ne se contente plus d‚Äôun fichier `.txt`, mais on recr√©e une **image compl√®te, lisible et localis√©e**.

---

üéØ **Objectif**

- Reconstituer visuellement une version "localis√©e" des pages manga
- Pr√©server les bulles, le fond, et l'esth√©tique g√©n√©rale
- R√©utiliser les coordonn√©es des bulles extraites lors de la d√©tection

---

üß™ **D√©marche mise en place (script `reinsert_translations.py`)**

1.  **Chargement des donn√©es**
   - Image nettoy√©e (g√©n√©r√©e √† l‚Äô√©tape 3)
   - Fichier `.json` contenant les traductions + coordonn√©es de chaque bulle

2.  **Utilisation des coordonn√©es de la bulle**
   - Chaque bulle poss√®de des coordonn√©es (`x_min`, `y_min`, `x_max`, `y_max`)
   - Ces donn√©es sont utilis√©es pour **positionner** le texte correctement dans la zone correspondante

3.  **R√©insertion du texte avec centrage automatique**
   - Le script mesure la largeur/hauteur disponibles
   - Il ajuste dynamiquement la **taille de la police** pour que le texte tienne dans la bulle
   - Le texte est centr√© automatiquement dans l‚Äôespace pr√©vu

4.  **Typographie adaptable**
   - Par d√©faut, une police classique (`arial.ttf`) est utilis√©e
   - Si indisponible, le script bascule sur la police syst√®me par d√©faut
   - √Ä terme, on pourrait ajuster la police selon le type de bulle

5.  **Export automatique**
   - L‚Äôimage finale est sauvegard√©e sous un nouveau nom (`image_clean_translated.png`)
   - L‚Äôensemble du processus est automatis√©

![image6](https://github.com/user-attachments/assets/a10993b6-b648-46a8-8412-634be79606f5)


### Cloner le d√©p√¥t

```bash
# Clonez le repo
git clone https://github.com/mHaashS/Manga-Bubble-Cleaner.git

# Placez-vous dans le dossier
cd Manga-Bubble-Cleaner

python -m venv venv
source venv/bin/activate

# Install requirements
pip install -r requirements.txt

# Install models
mkdir -p models
curl -L https://github.com/mHaashS/Manga-Bubble-Cleaner/releases/latest/download/model_final.pth \
     -o models/model_final.pth

# Clean Bubbles
python scripts/clean_bubbles.py path/to/image.png

# Translate Bubbles
python scripts/translate_bubble.py path/to/image.png

# Reinsert Translation
python scripts/reinsert_translation.py path/to/image_cleaned.png path/to/.translation.json
```

### Technologies utilis√©es
- Outil / Librairie	R√¥le
- Python 3.10:	 Langage principal du projet
- Detectron2: 	D√©tection des bulles avec Mask R-CNN (https://github.com/matterport/Mask_RCNN)
- EasyOCR:	Extraction de texte dans les bulles
- OpenCV: 	Traitement d‚Äôimages, masquage et nettoyage
- Pillow (PIL):	R√©insertion du texte dans l‚Äôimage
- OpenAI API:	Traduction automatique via GPT-3.5
- CVAT:	Annotation des donn√©es au format COCO
- json / txt export:	Format de sauvegarde des r√©sultats
